{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data/WASSA23_conv_level_with_labels_train.tsv'\n",
    "df = pd.read_table(data, header=0)\n",
    "new_col = []\n",
    "for names in df.columns:\n",
    "    new_col.append(names.strip())\n",
    "df.columns = new_col\n",
    "dataset = df.drop([\"conversation_id\", \"turn_id\", \"speaker_number\", \"article_id\", \"speaker_id\", \"essay_id\"], axis=1, inplace=True)\n",
    "\n",
    "X_data, y_data = df.loc[:, 'text'], df.drop('text', axis=1)\n",
    "X_train, X_test, y_train , y_test = train_test_split(X_data, y_data, train_size=0.8)\n",
    "#reset index of training examples\n",
    "X_train, X_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True)\n",
    "y_train, y_test = y_train.reset_index(drop=True), y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenization\n",
    "- remove stop word and punctuatuons, numbers\n",
    "- lematization\n",
    "- vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_preprocessor(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuations = set(string.punctuation)\n",
    "    lem = WordNetLemmatizer().lemmatize\n",
    "    sentence = word_tokenize(sentence)\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "    sentence = [word for word in sentence if word not in punctuations]\n",
    "    sentence_str = ' '.join(sentence)\n",
    "    sentence = lem(sentence_str)\n",
    "    return sentence #sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.6667, 2.    , 2.    ],\n",
       "        [2.    , 2.    , 3.    ],\n",
       "        [1.    , 1.3333, 0.6667],\n",
       "        ...,\n",
       "        [1.3333, 2.    , 1.6667],\n",
       "        [2.    , 4.3333, 2.6667],\n",
       "        [1.    , 0.6667, 0.3333]]),\n",
       " array([[0.    , 2.3333, 2.3333],\n",
       "        [1.3333, 1.6667, 1.6667],\n",
       "        [1.3333, 1.    , 2.6667],\n",
       "        ...,\n",
       "        [0.    , 2.    , 1.3333],\n",
       "        [1.3333, 2.    , 1.6667],\n",
       "        [1.6667, 2.    , 2.    ]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.apply(word_preprocessor)\n",
    "X_test = X_test.apply(word_preprocessor)\n",
    "\n",
    "#convert labels to array\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train[['EmotionalPolarity', 'Emotion', 'Empathy']]), np.array(y_test[['EmotionalPolarity', 'Emotion', 'Empathy']])\n",
    "y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=3000, stop_words='english', lowercase=True)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = X_train_vec.toarray()\n",
    "X_test_vec = X_test_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 3s 18ms/step - loss: 2.9584 - accuracy: 0.5581 - val_loss: 2.9940 - val_accuracy: 0.5757\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.9193 - accuracy: 0.5748 - val_loss: 2.9979 - val_accuracy: 0.5262\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.9015 - accuracy: 0.6330 - val_loss: 3.0059 - val_accuracy: 0.4812\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 2.8813 - accuracy: 0.6796 - val_loss: 3.0154 - val_accuracy: 0.5171\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8668 - accuracy: 0.7246 - val_loss: 3.0216 - val_accuracy: 0.5011\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8593 - accuracy: 0.7348 - val_loss: 3.0232 - val_accuracy: 0.4989\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8556 - accuracy: 0.7484 - val_loss: 3.0243 - val_accuracy: 0.4795\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8529 - accuracy: 0.7546 - val_loss: 3.0273 - val_accuracy: 0.4772\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8505 - accuracy: 0.7647 - val_loss: 3.0292 - val_accuracy: 0.4761\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8488 - accuracy: 0.7664 - val_loss: 3.0255 - val_accuracy: 0.4920\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8476 - accuracy: 0.7691 - val_loss: 3.0301 - val_accuracy: 0.4715\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8471 - accuracy: 0.7689 - val_loss: 3.0317 - val_accuracy: 0.4630\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8460 - accuracy: 0.7688 - val_loss: 3.0297 - val_accuracy: 0.4852\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8451 - accuracy: 0.7724 - val_loss: 3.0274 - val_accuracy: 0.4841\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8439 - accuracy: 0.7781 - val_loss: 3.0285 - val_accuracy: 0.4960\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8431 - accuracy: 0.7745 - val_loss: 3.0304 - val_accuracy: 0.4823\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 2.8424 - accuracy: 0.7830 - val_loss: 3.0334 - val_accuracy: 0.4653\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8424 - accuracy: 0.7786 - val_loss: 3.0309 - val_accuracy: 0.4823\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8416 - accuracy: 0.7853 - val_loss: 3.0309 - val_accuracy: 0.4863\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8401 - accuracy: 0.7876 - val_loss: 3.0307 - val_accuracy: 0.5006\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8393 - accuracy: 0.7897 - val_loss: 3.0346 - val_accuracy: 0.4801\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8384 - accuracy: 0.7972 - val_loss: 3.0345 - val_accuracy: 0.4767\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 2.8373 - accuracy: 0.7952 - val_loss: 3.0361 - val_accuracy: 0.4841\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8368 - accuracy: 0.7963 - val_loss: 3.0373 - val_accuracy: 0.4687\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8360 - accuracy: 0.8070 - val_loss: 3.0365 - val_accuracy: 0.4989\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8355 - accuracy: 0.8097 - val_loss: 3.0367 - val_accuracy: 0.4835\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8347 - accuracy: 0.8027 - val_loss: 3.0355 - val_accuracy: 0.4926\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8340 - accuracy: 0.8184 - val_loss: 3.0398 - val_accuracy: 0.4596\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8334 - accuracy: 0.8093 - val_loss: 3.0401 - val_accuracy: 0.4618\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8330 - accuracy: 0.8117 - val_loss: 3.0414 - val_accuracy: 0.4721\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 2.8327 - accuracy: 0.8098 - val_loss: 3.0414 - val_accuracy: 0.4869\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8323 - accuracy: 0.8198 - val_loss: 3.0403 - val_accuracy: 0.4835\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 2.8319 - accuracy: 0.8115 - val_loss: 3.0411 - val_accuracy: 0.4869\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8322 - accuracy: 0.8120 - val_loss: 3.0431 - val_accuracy: 0.4664\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8322 - accuracy: 0.8152 - val_loss: 3.0402 - val_accuracy: 0.4915\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8314 - accuracy: 0.8217 - val_loss: 3.0446 - val_accuracy: 0.4584\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8311 - accuracy: 0.8184 - val_loss: 3.0395 - val_accuracy: 0.4966\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 1s 17ms/step - loss: 2.8308 - accuracy: 0.8225 - val_loss: 3.0422 - val_accuracy: 0.4789\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 2.8303 - accuracy: 0.8219 - val_loss: 3.0406 - val_accuracy: 0.4892\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 1s 13ms/step - loss: 2.8303 - accuracy: 0.8204 - val_loss: 3.0419 - val_accuracy: 0.4886\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8300 - accuracy: 0.8185 - val_loss: 3.0423 - val_accuracy: 0.4596\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8297 - accuracy: 0.8282 - val_loss: 3.0404 - val_accuracy: 0.4892\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8300 - accuracy: 0.8292 - val_loss: 3.0430 - val_accuracy: 0.4601\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8299 - accuracy: 0.8165 - val_loss: 3.0405 - val_accuracy: 0.4915\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 2.8295 - accuracy: 0.8245 - val_loss: 3.0425 - val_accuracy: 0.4863\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 1s 9ms/step - loss: 2.8294 - accuracy: 0.8269 - val_loss: 3.0414 - val_accuracy: 0.4772\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 1s 10ms/step - loss: 2.8294 - accuracy: 0.8188 - val_loss: 3.0425 - val_accuracy: 0.4880\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8293 - accuracy: 0.8276 - val_loss: 3.0453 - val_accuracy: 0.4567\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 1s 15ms/step - loss: 2.8291 - accuracy: 0.8201 - val_loss: 3.0426 - val_accuracy: 0.4590\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 2.8289 - accuracy: 0.8232 - val_loss: 3.0429 - val_accuracy: 0.4784\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 3.0429 - accuracy: 0.4784\n",
      "Test loss: 3.0429117679595947\n",
      "Test accuracy: 0.4783599078655243\n"
     ]
    }
   ],
   "source": [
    "# Create a sequential model\n",
    "EEPD_Model = Sequential()\n",
    "EEPD_Model.add(Dense(100, activation='relu', input_dim=X_train_vec.shape[1]))\n",
    "EEPD_Model.add(Dense(80, activation='relu'))\n",
    "EEPD_Model.add(Dense(50, activation='relu'))\n",
    "EEPD_Model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "EEPD_Model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "EEPD_Model.fit(X_train_vec, y_train, epochs=20, batch_size=100, validation_data=(X_test_vec, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = EEPD_Model.evaluate(X_test_vec, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7020,), (7020, 3), (1756,), (1756, 3))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
